{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TC 5033\n",
    "## Deep Learning\n",
    "## Fully Connected Deep Neural Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activity 1a: Implementing a Multilayer Fully Connected Network using Numpy\n",
    "#### Non-graded activity (0 points)\n",
    "\n",
    "- Objective\n",
    "\n",
    "The primary objective of this activity is to deepen your understanding of Fully Connected Networks by implementing a multilayer network using only Numpy. You  are  given  the follosing starter code that solves the MNIST dataset problem. Your task is to read, understand, and then apply this knowledge to solve classification problems on other datasets such as the Kaggle ASL dataset (Starter code will be provided separately for that activity).\n",
    "\n",
    "- Instructions\n",
    "\n",
    "    Read and Understand the following Code: The provided starter code outlines the architecture of a Fully Connected Network designed to classify MNIST images. Go through the code to understand how each function and class is used to implement the network.\n",
    "\n",
    "    Understand the Math: Make sure you understand the math operations implemented in the code, especially during the forward and backward passes. This will involve matrix multiplications, activation functions, loss computations, and backpropagation.\n",
    "    \n",
    "- Experiment\n",
    "    You are encouraged to play with the code, change any hyperparameters and train the model, you should be able to achieve over 95% accuracy on the test set without problems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_images import get_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST path\n",
    "mnist_path = './mnist_raw/'\n",
    "x_train_num, y_train_num, x_test_num, y_test_num = get_images(mnist_path)\n",
    "\n",
    "x_train = x_train_num[:50000].reshape(50000, -1).astype(float)\n",
    "y_train = y_train_num[:50000].reshape(50000, 1)\n",
    "\n",
    "x_val = x_train_num[50000:].reshape(10000, -1).astype(float)\n",
    "y_val = y_train_num[50000:].reshape(10000, 1)\n",
    "\n",
    "x_test = x_test_num.copy().reshape(10000, -1).astype(float)\n",
    "y_test = y_test_num.copy().reshape(10000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33.39512885204082, 78.6661972212754, 0.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.mean(), x_train.std(), x_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(x_mean, x_std, x_data):\n",
    "    return (x_data - x_mean) / x_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = x_train.mean()\n",
    "x_std = x_train.std()\n",
    "\n",
    "x_train = normalise(x_mean, x_std, x_train)\n",
    "x_val = normalise(x_mean, x_std, x_val)\n",
    "x_test = normalise(x_mean, x_std, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-9.646705203355238e-18, 0.9999999999999997)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.mean(), x_train.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_number(image):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(image.squeeze(), cmap=plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La imagen muestreada representa un: 9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAR4AAAEeCAYAAABcyXrWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAHgElEQVR4nO3cz4tPfR/H8TmGIivKzGIWsiJZsBmzZWRWFkzZKayU1SCRLMZC/AESC2VlIxspCyXKjliQBVZSGlmN3xrnXt13yf2d79v8eM3g8dh+X32cK1fP69T16TRt2/YAJC1Z6AcA/j3CA8QJDxAnPECc8ABxwgPELZ3ux6Zp/L92YEbatm06/eaNB4gTHiBOeIA44QHihAeIEx4gTniAOOEB4oQHiBMeIE54gDjhAeKEB4gTHiBOeIA44QHihAeIEx4gTniAOOEB4oQHiBMeIE54gDjhAeKEB4gTHiBOeIA44QHihAeIEx4gTniAOOEB4oQHiBMeIE54gDjhAeKEB4gTHiBOeIA44QHihAeIEx4gTniAOOEB4oQHiBMeIE54gDjhAeKEB4gTHiBOeIA44QHihAeIEx4gTniAOOEB4oQHiFu60A/A4rN169bS7tSpU6Xdrl27ZvM4M3Lp0qXS7tChQ/P8JPw/3niAOOEB4oQHiBMeIE54gDjhAeKEB4gTHiBOeIC4pm3bzj82TecfWVRWr15d2o2Pj3fdHD58eLaP85OPHz/O2VlLl9Yu2/f29pZ2O3bs6Lq5f/9+6Sx+1rZt0+k3bzxAnPAAccIDxAkPECc8QJzwAHHCA8QJDxAnPECcby4vcn19faXd2NhYaVe5lfzhw4fSWSdPniztLly4UNpV7Ny5s7S7fft2abdy5crZPA4z5I0HiBMeIE54gDjhAeKEB4gTHiBOeIA44QHiXCBcIIODg6XdxYsXS7stW7aUdg8fPuy6GR0dLZ31+vXr0m4uff/+vbT78eNHaTc0NNR1c+/evdJZnz59Ku3wxgMsAOEB4oQHiBMeIE54gDjhAeKEB4gTHiBOeIA4N5fnQX9/f9fNnj17SmdVbyQ/f/68tNu/f3/XzULcSK66e/duaffmzZvS7vTp0103nz9/Lp117ty50g5vPMACEB4gTniAOOEB4oQHiBMeIE54gDjhAeKEB4hzc/k39Pb2lnZjY2NdN8ePHy+d9e7du9Ju27Ztpd3ExERpl3bs2LHS7siRI6VdX1/fbB7nJ5XvVPN7vPEAccIDxAkPECc8QJzwAHHCA8QJDxAnPECc8ABxTdu2nX9sms4//oP27dtX2l29erXrpnojeePGjaXd+/fvS7vFqvrN6PXr18/pn/vgwYOum+Hh4dJZ3759m+3j/FXatm06/eaNB4gTHiBOeIA44QHihAeIEx4gTniAOOEB4nz69DcMDAzM2VmXLl0q7f70i4E9PT09mzdv7rqZy0+V9vT09ExNTZV24+PjXTcuBs49bzxAnPAAccIDxAkPECc8QJzwAHHCA8QJDxAnPECcm8u/4cWLF3N21u7du0u7V69elXbXrl0r7Sq3cIeGhkpnVf8Z9u/f33WzatWq0llVJ06cKO3u3Lkzp38uNd54gDjhAeKEB4gTHiBOeIA44QHihAeIEx4gTniAuKZt284/Nk3nH/9BK1asKO1u3rzZdbN9+/bZPs5Pqt8Ynu7v+796e3tLZzVNU9rNpcnJydJu/fr1pd3bt29n8zhMo23bjv+CeOMB4oQHiBMeIE54gDjhAeKEB4gTHiBOeIA4nz79DZ8/fy7tRkdHu27Onz9fOuvAgQOl3Vy6fPlyaffs2bPSbu3atV03R48eLZ115cqV0s7FwMXNGw8QJzxAnPAAccIDxAkPECc8QJzwAHHCA8QJDxDn06fM2JIltf9u3bp1q+tmZGSkdNbevXtLu+vXr5d2zB+fPgUWFeEB4oQHiBMeIE54gDjhAeKEB4gTHiBOeIA4N5eZsWXLlpV2X79+7br58OFD6ayBgYHSbnJysrRj/ri5DCwqwgPECQ8QJzxAnPAAccIDxAkPECc8QJzwAHFLF/oB+HMNDw/P2VlTU1OlnRvJfwdvPECc8ABxwgPECQ8QJzxAnPAAccIDxAkPEOcCITO2bt260q5pOn4B838eP34828fhD+KNB4gTHiBOeIA44QHihAeIEx4gTniAOOEB4oQHiHNzmRkbGRkp7dq27bq5cePGbB+HP4g3HiBOeIA44QHihAeIEx4gTniAOOEB4oQHiBMeIK6Z7lZp0zTdr5zy1xkYGCjtHj16VNr19/d33UxMTJTOGh4eLu2ePn1a2jF/2rbt+LFtbzxAnPAAccIDxAkPECc8QJzwAHHCA8QJDxDn06f84uDBg6VdX19faVf59OmaNWtKZ23YsKG0c4FwcfPGA8QJDxAnPECc8ABxwgPECQ8QJzxAnPAAccIDxLm5zC+WL18e/zO/fPlS2j158mR+H4QIbzxAnPAAccIDxAkPECc8QJzwAHHCA8QJDxAnPECcm8v84uzZs6Xdpk2bSrvBwcGumzNnzpTOevnyZWnH4uaNB4gTHiBOeIA44QHihAeIEx4gTniAOOEB4oQHiGvatu38Y9N0/hFgGm3bNp1+88YDxAkPECc8QJzwAHHCA8QJDxAnPECc8ABxwgPECQ8QJzxAnPAAccIDxAkPECc8QJzwAHHCA8QJDxA37adPAeaDNx4gTniAOOEB4oQHiBMeIE54gLj/ADW3GkF6LycyAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnd_idx = np.random.randint(len(y_test))\n",
    "print(f'La imagen muestreada representa un: {y_test[rnd_idx, 0]}')\n",
    "plot_number(x_test_num[rnd_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equations\n",
    "\n",
    "\n",
    "$$z^1 = W^1 X + b^1$$\n",
    "\n",
    "$$a^1 = ReLU(z^1) $$\n",
    "\n",
    "$$z^2 = W^2 a^1 + b^2$$\n",
    "\n",
    "$$\\hat{y} = \\frac{e^{z^{2_k}}}{\\sum_j{e^{z_j}}}$$\n",
    "\n",
    "\n",
    "$$ \\mathcal{L}(\\hat{y}^{i}, y^{i}) =  - y^{i}  \\ln(\\hat{y}^{i}) = -\\ln(\\hat{y}^i)$$\n",
    "\n",
    "\n",
    "$$ \\mathcal{J}(w, b) =  \\frac{1}{num\\_samples} \\sum_{i=1}^{num\\_samples}-\\ln(\\hat{y}^{i})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creat Mini batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minibatches(mb_size, x, y, shuffle = True):\n",
    "    '''\n",
    "    x  #muestras, 784\n",
    "    y #muestras, 1\n",
    "    '''\n",
    "    assert x.shape[0] == y.shape[0], 'Error en cantidad de muestras'\n",
    "    total_data = x.shape[0]\n",
    "    if shuffle: \n",
    "        idxs = np.arange(total_data)\n",
    "        np.random.shuffle(idxs)\n",
    "        x = x[idxs]\n",
    "        y = y[idxs]  \n",
    "    return ((x[i:i+mb_size], y[i:i+mb_size]) for i in range(0, total_data, mb_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nuestra clase Linear, ReLU y Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class np_tensor(np.ndarray): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0, 0])\n",
    "\n",
    "b = a.view(np_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.np_tensor"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np_tensor([ True,  True])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a is b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Clase Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    def __init__(self, input_size, output_size):\n",
    "        '''\n",
    "        Init parameters utilizando Kaiming He\n",
    "        '''\n",
    "        self.W = (np.random.randn(output_size, input_size) / np.sqrt(input_size/2)).view(np_tensor)\n",
    "        self.b = (np.zeros((output_size, 1))).view(np_tensor)\n",
    "    def __call__(self, X): # esta el foward de la clase lineal\n",
    "        Z = self.W @ X + self.b\n",
    "        return Z\n",
    "    def backward(self, X, Z):\n",
    "        X.grad = self.W.T @ Z.grad\n",
    "        self.W.grad = Z.grad @ X.T\n",
    "        self.b.grad = np.sum(Z.grad, axis = 1, keepdims=True)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clase ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    def __call__(self, Z):\n",
    "        return np.maximum(0, Z)\n",
    "    def backward(self, Z, A):\n",
    "        Z.grad = A.grad.copy()\n",
    "        Z.grad[Z <= 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clase Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Sequential_layers():\n",
    "    def __init__(self, layers):\n",
    "        '''\n",
    "        layers - lista que contiene objetos de tipo Linear, ReLU\n",
    "        '''\n",
    "        self.layers = layers\n",
    "        self.x = None\n",
    "        self.outputs = {}\n",
    "    def __call__(self, X):\n",
    "        self.x = X \n",
    "        self.outputs['l0'] = self.x\n",
    "        for i, layer in enumerate(self.layers, 1):\n",
    "            self.x = layer(self.x)\n",
    "            self.outputs['l'+str(i)]=self.x\n",
    "        return self.x\n",
    "    def backward(self):\n",
    "        for i in reversed(range(len(self.layers))):\n",
    "            self.layers[i].backward(self.outputs['l'+str(i)], self.outputs['l'+str(i+1)])\n",
    "    def update(self, learning_rate = 1e-3):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, ReLU): continue\n",
    "            layer.W = layer.W - learning_rate * layer.W.grad\n",
    "            layer.b = layer.b - learning_rate * layer.b.grad\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.__call__(X))            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def softmaxXEntropy(x, y):\n",
    "    batch_size = x.shape[1]\n",
    "    exp_scores = np.exp(x)\n",
    "    probs = exp_scores / exp_scores.sum(axis = 0)\n",
    "    preds = probs.copy()\n",
    "    # Costo\n",
    "    y_hat = probs[y.squeeze(), np.arange(batch_size)]\n",
    "    cost = np.sum(-np.log(y_hat)) / batch_size\n",
    "    # Calcular gradientes\n",
    "    probs[y.squeeze(), np.arange(batch_size)] -= 1 #dl/dx\n",
    "    x.grad = probs.copy()\n",
    "    \n",
    "    return preds, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def train(model, epochs, mb_size=128, learning_rate = 1e-3):\n",
    "    for epoch in range(epochs):\n",
    "        for i, (x, y) in enumerate(create_minibatches(mb_size, x_train, y_train)):\n",
    "            scores = model(x.T.view(np_tensor))\n",
    "            _, cost = softmaxXEntropy(scores, y)\n",
    "            model.backward()\n",
    "            model.update(learning_rate)\n",
    "        print(f'costo: {cost}, accuracy: {accuracy(x_val, y_val, mb_size)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def accuracy(x, y, mb_size):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (x, y) in enumerate(create_minibatches(mb_size, x, y)):\n",
    "        pred = model(x.T.view(np_tensor))\n",
    "        correct += np.sum(np.argmax(pred, axis=0) == y.squeeze())\n",
    "        total += pred.shape[1]\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential_layers([Linear(784, 200), ReLU(), Linear(200, 200), ReLU(), Linear(200, 10)])\n",
    "mb_size = 512\n",
    "learning_rate = 1e-4\n",
    "epochs = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "costo: 0.3408139533787805, accuracy: 0.916\n",
      "costo: 0.25749495060192684, accuracy: 0.9359\n",
      "costo: 0.20673264678494457, accuracy: 0.9435\n",
      "costo: 0.14720644482702122, accuracy: 0.9506\n",
      "costo: 0.18189130041755966, accuracy: 0.9567\n",
      "costo: 0.18274751235582756, accuracy: 0.959\n",
      "costo: 0.13328855386540225, accuracy: 0.9616\n",
      "costo: 0.11284696656239948, accuracy: 0.963\n",
      "costo: 0.10704618738345766, accuracy: 0.966\n",
      "costo: 0.0626636387250584, accuracy: 0.9665\n",
      "costo: 0.0867885659932057, accuracy: 0.9677\n",
      "costo: 0.06115343801963583, accuracy: 0.9684\n",
      "costo: 0.06623363514661243, accuracy: 0.9702\n",
      "costo: 0.0708447648177598, accuracy: 0.97\n",
      "costo: 0.0969387376766539, accuracy: 0.9701\n",
      "costo: 0.0899043425563203, accuracy: 0.9711\n",
      "costo: 0.06898864563081634, accuracy: 0.9715\n",
      "costo: 0.06657742921443839, accuracy: 0.9723\n",
      "costo: 0.028633711258084244, accuracy: 0.9725\n",
      "costo: 0.09671823516510039, accuracy: 0.9719\n"
     ]
    }
   ],
   "source": [
    "train(model, epochs, mb_size, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9708\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(x_test, y_test, mb_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el valor predicho es: 9, el valor real es:9\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(len(y_test))\n",
    "plot_number(x_test_num[idx])\n",
    "pred = model.predict(x_test[idx].reshape(-1, 1))\n",
    "print(f'el valor predicho es: {pred}, el valor real es:{y_test[idx][0]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
